{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e09267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu.Tiwari\\OneDrive\\agentic_ai_langchain_azure\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f910d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eca06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910e6617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How are you today? If you’d like, I can say something about a topic you choose.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 352, 'prompt_tokens': 10, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-DAqcrRb1v6oLzpZLLmzc7W0mIdmVP', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='lc_run--019c7450-4b55-7fc1-a52b-b97bba1abc36-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 10, 'output_tokens': 352, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}\n"
     ]
    }
   ],
   "source": [
    "## smoke test\n",
    "response = llm.invoke(\"say something in english\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481818ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#prompt = ChatPromptTemplate.from_messages([\n",
    "#    (\"system\", \"You are a sentiment analyst. Be consice in one sentence.\"),\n",
    "#    (\"human\", \"Analyse the sentiment of this text: {text}\"),])\n",
    "#\n",
    "#chain = prompt | llm\n",
    "#result = chain.invoke({\"text\": \"I recently reviewed my latest bill and found a charge that I didn’t recognize. The support I received when I called billing was polite and patient, which I appreciated. The representative explained the charges clearly and showed me how to read the bill line items step by step. I asked for a temporary adjustment while the issue was investigated, and the agent assured me they would escalate it and keep me updated. The explanation helped me understand where the duplicate item came from, which reduced my frustration. However, I still felt a bit uncertain about the next steps until the investigation confirmed the error. I value transparency, so I appreciated the email summary that outlined the investigation timeline. Overall, this experience was better than previous billing encounters because I felt listened to and informed. I would recommend continuing to provide proactive updates if similar issues come up in the future.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d19e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'positive', 'score': 0.65, 'emotion': 'joy'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SentimentResult(BaseModel):\n",
    "    sentiment: str = Field(description=\"positive, negative, or neutral\")\n",
    "    score: float = Field(description=\"confidence score 0.0 to 1.0\")\n",
    "    emotion: str = Field(description=\"primary emotion detected\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=SentimentResult)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a sentiment analyst. Return JSON only.\"),\n",
    "    (\"human\", \"{format_instructions}\\n\\nText: {text}\")\n",
    "]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\"text\": \"I love this product but shipping was slow.\"})\n",
    "print(result)  # → {'sentiment': 'positive', 'score': 0.75, 'emotion': 'satisfaction'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef00750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JsonOutputParser(pydantic_object=<class '__main__.SentimentResult'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcbbfd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentiment agent\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SentimentResult(BaseModel):\n",
    "    sentiment: str\n",
    "    score: float\n",
    "    emotion: str\n",
    "    key_phrases: list[str]\n",
    "\n",
    "sentiment_parser = JsonOutputParser(pydantic_object=SentimentResult)    \n",
    "\n",
    "sentiment_prompt_text = open(\"sentiment_prompt\").read()\n",
    "sentiment_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", sentiment_prompt_text + \" {format_instructions}\"),\n",
    "    (\"human\", \"Analyse the customer message: \\n\\n{text}\")]).partial(format_instructions=sentiment_parser.get_format_instructions())\n",
    "\n",
    "sentiment_chain = sentiment_prompt | llm | sentiment_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationOutput(BaseModel):\n",
    "    recommended_actions: list[str]\n",
    "    priority: str # low, medium, high, critical\n",
    "    department: str # customer service, technical support, billing, etc.\n",
    "    suggested_response: str\n",
    "\n",
    "rec_parser = JsonOutputParser(pydantic_object=RecommendationOutput)\n",
    "\n",
    "rec_prompt_text = open(\"recommendation_prompt\").read()\n",
    "rec_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", rec_prompt_text + \" {format_instructions}\"),\n",
    "    (\"human\", \"\"\"Customer message: {text}\n",
    "    Sentiment analysis result: {sentiment_result}\n",
    "    Provide recommendation.\"\"\")]).partial(format_instructions=rec_parser.get_format_instructions())\n",
    "\n",
    "rec_chain = rec_prompt | llm | rec_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50459398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EscalationOuptput(BaseModel):\n",
    "    should_escalate: bool\n",
    "    escalation_level: str # none | low | medium | high\n",
    "    reason: str\n",
    "    urgency_score: float # 1-10\n",
    "    suggested_sla_hours: int\n",
    "\n",
    "esc_parser = JsonOutputParser(pydantic_object=EscalationOuptput)\n",
    "\n",
    "esc_prompt_text = open(\"escalation_prompt\").read()\n",
    "esc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", esc_prompt_text + \" {format_instructions}\"),\n",
    "    (\"human\", \"\"\"Customer message: {text}\n",
    "    Sentiment analysis result: {sentiment_result}\n",
    "    Recommendation result: {rec_result}\n",
    "    Should this be escalated?\"\"\")]).partial(format_instructions=esc_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
